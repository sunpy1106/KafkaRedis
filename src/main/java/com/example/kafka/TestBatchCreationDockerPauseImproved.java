package com.example.kafka;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;

/**
 * æµ‹è¯•ç±»ï¼šæ”¹è¿›çš„ Docker pause æ–¹æ¡ˆè§¦å‘ "batch creation" è¶…æ—¶
 *
 * ç­–ç•¥:
 *  - ä½¿ç”¨ linger.ms=5000 å»¶è¿Ÿ batch å‘é€
 *  - å…ˆå‘é€é¢„çƒ­æ¶ˆæ¯ç¼“å­˜ metadata
 *  - å‘é€æ¶ˆæ¯ååœ¨ linger æ—¶é—´å†…æš‚åœ Kafka broker
 *  - Batch å·²åˆ›å»ºä½†æ— æ³•å‘é€
 *  - ç­‰å¾… delivery.timeout.ms è¶…æ—¶
 *
 * ç›®æ ‡é”™è¯¯: "X ms has passed since batch creation"
 *
 * ä½¿ç”¨æ–¹æ³•:
 *  1. è¿è¡Œæ­¤ç¨‹åº
 *  2. ç¨‹åºä¼šè‡ªåŠ¨åœ¨åˆé€‚çš„æ—¶æœºæç¤ºæ‰§è¡Œ docker pause
 *  3. ç­‰å¾…è¶…æ—¶
 *  4. ç¨‹åºç»“æŸåæ‰§è¡Œ docker unpause
 */
public class TestBatchCreationDockerPauseImproved {
    private static final Logger logger = LoggerFactory.getLogger(TestBatchCreationDockerPauseImproved.class);
    private static final AtomicBoolean shouldPause = new AtomicBoolean(false);

    public static void main(String[] args) {
        logger.info("========== æµ‹è¯•æ”¹è¿›çš„ Docker pause è§¦å‘ Batch Creation è¶…æ—¶ ==========\n");

        testDockerPauseImproved();

        logger.info("\n========== æµ‹è¯•å®Œæˆ ==========");
    }

    private static void testDockerPauseImproved() {
        logger.info("ã€æµ‹è¯•ã€‘æ”¹è¿›çš„ Docker pause æ–¹æ¡ˆ");
        logger.info("ç­–ç•¥: ä½¿ç”¨ linger.ms å»¶è¿Ÿå‘é€ï¼Œåœ¨æ­¤æœŸé—´æš‚åœ broker\n");

        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");  // çœŸå® Kafka

        // å…³é”®é…ç½®ï¼šä½¿ç”¨ linger.ms å»¶è¿Ÿ batch å‘é€
        props.put("acks", "1");
        props.put("delivery.timeout.ms", "30000");  // 30ç§’è¶…æ—¶
        props.put("request.timeout.ms", "10000");
        props.put("linger.ms", "5000");  // âš ï¸ å…³é”®ï¼šå»¶è¿Ÿ5ç§’å‘é€ï¼Œç»™æˆ‘ä»¬æ—¶é—´æš‚åœbroker
        props.put("batch.size", "16384");
        props.put("retries", "3");
        props.put("retry.backoff.ms", "100");

        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());

        KafkaProducer<String, String> producer = null;
        final CountDownLatch warmupLatch = new CountDownLatch(1);
        final CountDownLatch testLatch = new CountDownLatch(10);
        final long startTime[] = {0};

        // å¯åŠ¨ä¸€ä¸ªçº¿ç¨‹ç›‘æ§ä½•æ—¶æš‚åœ
        Thread pauseThread = new Thread(() -> {
            while (!shouldPause.get()) {
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    break;
                }
            }

            logger.warn("\n");
            logger.warn("âš ï¸âš ï¸âš ï¸ ç«‹å³æ‰§è¡Œ:");
            logger.warn("   docker pause kafka-broker");
            logger.warn("âš ï¸âš ï¸âš ï¸ ä½ æœ‰ 3 ç§’æ—¶é—´æ‰§è¡Œï¼");
            logger.warn("\n");

            try {
                Thread.sleep(3000);
            } catch (InterruptedException e) {
                // ignore
            }

            logger.info("å‡è®¾ Kafka broker å·²è¢«æš‚åœï¼Œç»§ç»­ç­‰å¾…è¶…æ—¶...\n");
        });
        pauseThread.setDaemon(true);
        pauseThread.start();

        try {
            logger.info("1. åˆ›å»º KafkaProducer (linger.ms=5000)...");
            producer = new KafkaProducer<>(props);
            logger.info("   âœ… KafkaProducer åˆ›å»ºæˆåŠŸ\n");

            logger.info("2. å‘é€é¢„çƒ­æ¶ˆæ¯ï¼ˆç¼“å­˜ metadataï¼‰...");

            // å…ˆç”¨ä¸€ä¸ªæ²¡æœ‰lingerçš„producerå‘é€é¢„çƒ­æ¶ˆæ¯
            Properties warmupProps = new Properties();
            warmupProps.putAll(props);
            warmupProps.put("linger.ms", "0");  // é¢„çƒ­æ¶ˆæ¯ç«‹å³å‘é€

            KafkaProducer<String, String> warmupProducer = new KafkaProducer<>(warmupProps);
            ProducerRecord<String, String> warmupRecord =
                new ProducerRecord<>("test-topic", "warmup-key", "warmup-value");

            warmupProducer.send(warmupRecord, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception != null) {
                        logger.error("é¢„çƒ­æ¶ˆæ¯å‘é€å¤±è´¥: {}", exception.getMessage());
                    } else {
                        logger.info("   âœ… é¢„çƒ­æ¶ˆæ¯å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                            metadata.partition(), metadata.offset());
                        logger.info("   âœ… Metadata å·²ç¼“å­˜\n");
                    }
                    warmupLatch.countDown();
                }
            });

            // ç­‰å¾…é¢„çƒ­å®Œæˆ
            if (!warmupLatch.await(10, TimeUnit.SECONDS)) {
                logger.error("é¢„çƒ­æ¶ˆæ¯å‘é€è¶…æ—¶");
                return;
            }

            warmupProducer.close();

            logger.info("3. å‘é€10æ¡æµ‹è¯•æ¶ˆæ¯ï¼ˆbatch å°†åœ¨5ç§’åå‘é€ï¼‰...");
            logger.info("   ç”±äº linger.ms=5000ï¼Œæ¶ˆæ¯ä¼šåœ¨ batch ä¸­ç­‰å¾…5ç§’\n");

            startTime[0] = System.currentTimeMillis();

            // å‘é€10æ¡æ¶ˆæ¯ï¼Œå®ƒä»¬ä¼šè¢«æ”¾å…¥åŒä¸€ä¸ª batch
            for (int i = 1; i <= 10; i++) {
                final int msgNum = i;
                ProducerRecord<String, String> record =
                    new ProducerRecord<>("test-topic", "key-" + i, "value-" + i);

                producer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metadata, Exception exception) {
                        long elapsed = System.currentTimeMillis() - startTime[0];

                        if (exception != null) {
                            logger.error("\nâŒ æ¶ˆæ¯ #{} å‘é€å¤±è´¥ï¼è€—æ—¶: {}ms ({} ç§’)",
                                msgNum, elapsed, elapsed / 1000);
                            logger.error("å¼‚å¸¸ç±»å‹: {}", exception.getClass().getName());
                            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", exception.getMessage());

                            String message = exception.getMessage();
                            if (message != null) {
                                // æ£€æŸ¥å„ç§å¯èƒ½çš„ batch creation ç›¸å…³æ¶ˆæ¯
                                if (message.contains("batch creation") ||
                                    message.contains("since batch") ||
                                    message.contains("since last append")) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("Expiring") &&
                                          (message.contains("record") || message.contains("batch"))) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ è§¦å‘äº† Batch/Record è¿‡æœŸè¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… è¿™å¾ˆå¯èƒ½å°±æ˜¯ batch creation è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("30") && message.contains("ms")) {
                                    logger.info("\nğŸ¯ è§¦å‘äº†30ç§’è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("timeout") || message.contains("Timeout")) {
                                    logger.info("\nâš ï¸  è§¦å‘äº†è¶…æ—¶å¼‚å¸¸");
                                    logger.info("   æ¶ˆæ¯: {}", message);
                                } else {
                                    logger.warn("\nâš ï¸  è§¦å‘äº†å…¶ä»–å¼‚å¸¸");
                                    logger.warn("   æ¶ˆæ¯: {}", message);
                                }
                            }

                            if (exception.getCause() != null) {
                                logger.error("æ ¹æœ¬åŸå› : {}", exception.getCause().getClass().getName());
                                logger.error("åŸå› æ¶ˆæ¯: {}", exception.getCause().getMessage());
                            }

                        } else {
                            logger.info("âœ… æ¶ˆæ¯ #{} å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                                msgNum, metadata.partition(), metadata.offset());
                        }

                        testLatch.countDown();
                    }
                });

                logger.info("   æ¶ˆæ¯ #{} å·²åŠ å…¥ batch", i);
            }

            logger.info("\nâœ… æ‰€æœ‰æ¶ˆæ¯å·²åŠ å…¥ batch");
            logger.info("â° Batch å°†åœ¨ 5 ç§’åï¼ˆlinger.msï¼‰å°è¯•å‘é€");
            logger.info("ğŸ“Œ ç°åœ¨æ˜¯æš‚åœ Kafka broker çš„æœ€ä½³æ—¶æœºï¼\n");

            // è§¦å‘æš‚åœæç¤º
            shouldPause.set(true);

            // ç­‰å¾…2ç§’ï¼Œè®©ç”¨æˆ·æœ‰æ—¶é—´æš‚åœ
            Thread.sleep(2000);

            logger.warn("\nç­‰å¾… delivery.timeout.ms=30ç§’ è¶…æ—¶...\n");

            // å¯åŠ¨å€’è®¡æ—¶çº¿ç¨‹
            Thread countdownThread = new Thread(() -> {
                for (int i = 30; i > 0; i--) {
                    if (i % 10 == 0 || i <= 5) {
                        logger.info("   è¿˜éœ€ç­‰å¾…: {} ç§’...", i);
                    }
                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                        break;
                    }
                    if (testLatch.getCount() == 0) {
                        logger.info("   æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæ¯•");
                        break;
                    }
                }
            });
            countdownThread.setDaemon(true);
            countdownThread.start();

            // ç­‰å¾…æ‰€æœ‰ Callback å®Œæˆï¼ˆæœ€å¤š 40 ç§’ï¼‰
            boolean completed = testLatch.await(40, TimeUnit.SECONDS);

            if (!completed) {
                logger.warn("âš ï¸  ç­‰å¾…è¶…æ—¶ï¼Œéƒ¨åˆ† Callback æœªæ‰§è¡Œ");
                logger.warn("   å¯èƒ½éœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´");
            }

        } catch (Exception e) {
            logger.error("\nå‘ç”Ÿå…¶ä»–å¼‚å¸¸: {}", e.getClass().getName());
            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", e.getMessage(), e);

        } finally {
            if (producer != null) {
                try {
                    logger.info("\n4. å…³é—­ KafkaProducer...");
                    producer.close(5, TimeUnit.SECONDS);  // æœ€å¤šç­‰å¾…5ç§’
                    logger.info("   KafkaProducer å·²å…³é—­\n");
                } catch (Exception e) {
                    logger.debug("å…³é—­ producer æ—¶å‘ç”Ÿå¼‚å¸¸", e);
                }
            }

            logger.warn("\nâš ï¸  è®°å¾—æ¢å¤ Kafka broker:");
            logger.warn("   docker unpause kafka-broker\n");
        }
    }
}