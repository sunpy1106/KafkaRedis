package com.example.kafka;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.*;
import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * æµ‹è¯•ç±»ï¼šä½¿ç”¨ fio åˆ¶é€ ç£ç›˜ I/O å‹åŠ›è§¦å‘ "batch creation" è¶…æ—¶
 *
 * åŸç†:
 *  - ä½¿ç”¨ fio åœ¨ Kafka æ•°æ®ç›®å½•åˆ¶é€ å¤§é‡åŒæ­¥å†™å…¥å‹åŠ›
 *  - ç£ç›˜ I/O é˜Ÿåˆ—é¥±å’Œï¼Œå¯¼è‡´ Kafka çš„ fsync é˜»å¡
 *  - æ¶ˆæ¯åœ¨ batch ä¸­ç­‰å¾…è¶…è¿‡ delivery.timeout.ms åè¶…æ—¶
 *
 * ç›®æ ‡é”™è¯¯: "X ms has passed since batch creation"
 *
 * ä½¿ç”¨æ–¹æ³•:
 *   mvn exec:java -Dexec.mainClass="com.example.kafka.TestBatchCreationFioSlowDisk"
 */
public class TestBatchCreationFioSlowDisk {
    private static final Logger logger = LoggerFactory.getLogger(TestBatchCreationFioSlowDisk.class);

    private static final String BOOTSTRAP_SERVERS = "localhost:19092";
    private static final String TOPIC = "test-topic";

    // Kafka æ•°æ®å·è·¯å¾„
    private static final String KAFKA_DATA_PATH = "/var/lib/docker/volumes/kafkaredis_kafka_data/_data";

    // è¶…æ—¶é…ç½®
    private static final int DELIVERY_TIMEOUT_MS = 30000;  // 30ç§’
    private static final int REQUEST_TIMEOUT_MS = 10000;   // 10ç§’

    // fio è¿›ç¨‹
    private static Process fioProcess = null;

    public static void main(String[] args) {
        logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
        logger.info("â•‘   FIO ç£ç›˜å‹åŠ›æ–¹æ³•è§¦å‘ Batch Creation è¶…æ—¶                     â•‘");
        logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

        // æ£€æŸ¥ fio æ˜¯å¦å¯ç”¨
        if (!checkFioAvailable()) {
            logger.error("âŒ fio æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: yum install -y fio æˆ– apt install -y fio");
            return;
        }

        runTest();

        logger.info("\n========== æµ‹è¯•å®Œæˆ ==========");
    }

    private static void runTest() {
        KafkaProducer<String, String> producer = null;
        final AtomicBoolean fioRunning = new AtomicBoolean(false);
        final CountDownLatch warmupLatch = new CountDownLatch(1);
        final CountDownLatch testLatch = new CountDownLatch(20);
        final long[] startTime = {0};
        final AtomicInteger successCount = new AtomicInteger(0);
        final AtomicInteger failureCount = new AtomicInteger(0);
        final AtomicBoolean targetErrorTriggered = new AtomicBoolean(false);

        try {
            // 1. åˆ›å»º Producer
            Properties props = new Properties();
            props.put("bootstrap.servers", BOOTSTRAP_SERVERS);
            props.put("key.serializer", StringSerializer.class.getName());
            props.put("value.serializer", StringSerializer.class.getName());
            props.put("acks", "all");
            props.put("delivery.timeout.ms", String.valueOf(DELIVERY_TIMEOUT_MS));
            props.put("request.timeout.ms", String.valueOf(REQUEST_TIMEOUT_MS));
            props.put("max.block.ms", "15000");
            props.put("linger.ms", "500");
            props.put("batch.size", "16384");
            props.put("retries", "3");
            props.put("retry.backoff.ms", "1000");

            logger.info("1. åˆ›å»º KafkaProducer...");
            producer = new KafkaProducer<>(props);
            logger.info("   âœ… KafkaProducer åˆ›å»ºæˆåŠŸ\n");

            // 2. å‘é€é¢„çƒ­æ¶ˆæ¯
            logger.info("2. å‘é€é¢„çƒ­æ¶ˆæ¯ï¼ˆç¼“å­˜ metadataï¼‰...");
            producer.send(
                new ProducerRecord<>(TOPIC, "warmup", "warmup-" + System.currentTimeMillis()),
                (metadata, exception) -> {
                    if (exception != null) {
                        logger.error("   âŒ é¢„çƒ­å¤±è´¥: {}", exception.getMessage());
                    } else {
                        logger.info("   âœ… é¢„çƒ­æˆåŠŸ - Partition: {}, Offset: {}",
                            metadata.partition(), metadata.offset());
                    }
                    warmupLatch.countDown();
                }
            );

            if (!warmupLatch.await(15, TimeUnit.SECONDS)) {
                logger.error("   âŒ é¢„çƒ­è¶…æ—¶");
                return;
            }
            producer.flush();
            logger.info("   âœ… Metadata å·²ç¼“å­˜\n");

            Thread.sleep(2000);

            // 3. å¯åŠ¨ fio åˆ¶é€  I/O å‹åŠ›
            logger.info("3. å¯åŠ¨ fio åˆ¶é€ ç£ç›˜ I/O å‹åŠ›...");
            logger.info("   â””â”€ ç›®æ ‡ç›®å½•: {}", KAFKA_DATA_PATH);

            if (startFioStress()) {
                fioRunning.set(true);
                logger.info("   âœ… fio å·²å¯åŠ¨");
                logger.info("   ğŸ“‹ å‚æ•°: 8ä¸ªå¹¶å‘ä½œä¸š, 4Kéšæœºå†™, fsyncå¼ºåˆ¶åˆ·ç›˜\n");
            } else {
                logger.error("   âŒ å¯åŠ¨ fio å¤±è´¥");
                return;
            }

            // ç­‰å¾… I/O å‹åŠ›ç”Ÿæ•ˆ
            logger.info("   â³ ç­‰å¾… 5 ç§’è®© I/O å‹åŠ›å……åˆ†ç”Ÿæ•ˆ...\n");
            Thread.sleep(5000);

            // 4. å‘é€æµ‹è¯•æ¶ˆæ¯
            logger.info("4. å‘é€ 20 æ¡æµ‹è¯•æ¶ˆæ¯...");
            logger.info("   â””â”€ ç£ç›˜ I/O é¥±å’Œä¼šå¯¼è‡´ fsync é˜»å¡");
            logger.info("   â””â”€ ç­‰å¾… delivery.timeout.ms={} ç§’åè¶…æ—¶\n", DELIVERY_TIMEOUT_MS / 1000);

            startTime[0] = System.currentTimeMillis();

            for (int i = 1; i <= 20; i++) {
                final int msgNum = i;
                String value = "fio-test-value-" + i + "-" + System.currentTimeMillis();
                ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC, "key-" + i, value);

                producer.send(record, (metadata, exception) -> {
                    long elapsed = System.currentTimeMillis() - startTime[0];

                    if (exception != null) {
                        failureCount.incrementAndGet();
                        String errMsg = exception.getMessage();

                        logger.error("\nâ•”â•â•â•â• æ¶ˆæ¯ #{} å‘é€å¤±è´¥ â•â•â•â•â•—", msgNum);
                        logger.error("â•‘ è€—æ—¶: {}ms ({:.1f}ç§’)", elapsed, elapsed / 1000.0);
                        logger.error("â•‘ ç±»å‹: {}", exception.getClass().getSimpleName());
                        logger.error("â•‘ æ¶ˆæ¯: {}", errMsg);

                        if (errMsg != null && (errMsg.contains("batch creation") ||
                            errMsg.contains("since batch") ||
                            errMsg.contains("Expiring"))) {
                            targetErrorTriggered.set(true);
                            logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
                            logger.info("â•‘ ğŸ¯ğŸ¯ğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼  â•‘");
                            logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
                        }
                        logger.error("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
                    } else {
                        successCount.incrementAndGet();
                        logger.info("   âœ… æ¶ˆæ¯ #{} æˆåŠŸ ({}ms)", msgNum, elapsed);
                    }

                    testLatch.countDown();
                });

                if (i % 10 == 0) {
                    logger.info("   â””â”€ å·²æäº¤ {} æ¡æ¶ˆæ¯", i);
                }
            }

            // 5. ç­‰å¾…ç»“æœ
            logger.info("\n5. ç­‰å¾…æ¶ˆæ¯å¤„ç†...");

            Thread countdown = new Thread(() -> {
                int totalSeconds = DELIVERY_TIMEOUT_MS / 1000 + 15;
                for (int i = totalSeconds; i > 0; i--) {
                    if (testLatch.getCount() == 0) break;
                    if (i % 10 == 0 || i <= 5) {
                        logger.info("   â± å‰©ä½™ {} ç§’ | æˆåŠŸ: {} | å¤±è´¥: {}",
                            i, successCount.get(), failureCount.get());
                    }
                    try { Thread.sleep(1000); } catch (InterruptedException e) { break; }
                }
            });
            countdown.setDaemon(true);
            countdown.start();

            boolean completed = testLatch.await(DELIVERY_TIMEOUT_MS + 20000, TimeUnit.MILLISECONDS);

            // 6. è¾“å‡ºç»“æœ
            logger.info("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
            logger.info("â•‘           æµ‹è¯•ç»“æœæ±‡æ€»                â•‘");
            logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
            logger.info("â•‘ æˆåŠŸå‘é€:    {:2}                      â•‘", successCount.get());
            logger.info("â•‘ å‘é€å¤±è´¥:    {:2}                      â•‘", failureCount.get());
            logger.info("â•‘ ç›®æ ‡é”™è¯¯:    {}                     â•‘", targetErrorTriggered.get() ? "âœ…" : "âŒ");
            logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

            if (targetErrorTriggered.get()) {
                logger.info("\nğŸ‰ ä½¿ç”¨ fio I/O å‹åŠ›æˆåŠŸå¤ç° Batch Creation è¶…æ—¶ï¼");
            } else if (successCount.get() == 20) {
                logger.info("\nâš ï¸ æ‰€æœ‰æ¶ˆæ¯éƒ½æˆåŠŸäº†ï¼Œå¯èƒ½éœ€è¦å¢åŠ  fio å‹åŠ›");
                logger.info("   å»ºè®®: å¢åŠ  numjobs æˆ– iodepth å‚æ•°");
            }

        } catch (Exception e) {
            logger.error("æµ‹è¯•å¼‚å¸¸: {}", e.getMessage(), e);
        } finally {
            // 7. åœæ­¢ fio
            if (fioRunning.get()) {
                logger.info("\n6. åœæ­¢ fio...");
                stopFioStress();
                logger.info("   âœ… fio å·²åœæ­¢");

                // æ¸…ç†æµ‹è¯•æ–‡ä»¶
                cleanupFioFiles();
                logger.info("   âœ… æµ‹è¯•æ–‡ä»¶å·²æ¸…ç†");
            }

            if (producer != null) {
                logger.info("\n7. å…³é—­ KafkaProducer...");
                try {
                    producer.close(5, TimeUnit.SECONDS);
                    logger.info("   âœ… å·²å…³é—­");
                } catch (Exception e) {
                    logger.debug("å…³é—­å¼‚å¸¸", e);
                }
            }
        }
    }

    private static boolean checkFioAvailable() {
        try {
            Process p = Runtime.getRuntime().exec(new String[]{"which", "fio"});
            return p.waitFor() == 0;
        } catch (Exception e) {
            return false;
        }
    }

    private static boolean startFioStress() {
        try {
            // æ„å»º fio å‘½ä»¤ - åœ¨ Kafka æ•°æ®ç›®å½•åˆ¶é€ æå¤§çš„åŒæ­¥å†™å…¥å‹åŠ›
            String[] cmd = {
                "fio",
                "--name=kafka-stress",
                "--directory=" + KAFKA_DATA_PATH,
                "--rw=randwrite",           // éšæœºå†™
                "--bs=4k",                  // 4K å—å¤§å°
                "--size=500M",              // æ¯ä¸ªä½œä¸šå†™ 500MB
                "--numjobs=8",              // 8 ä¸ªå¹¶å‘ä½œä¸š
                "--iodepth=64",             // I/O é˜Ÿåˆ—æ·±åº¦ 64
                "--direct=1",               // ç»•è¿‡ç¼“å­˜
                "--fsync=1",                // æ¯æ¬¡å†™å…¥éƒ½ fsync
                "--group_reporting",
                "--time_based",
                "--runtime=120"             // è¿è¡Œ 120 ç§’
            };

            logger.info("   æ‰§è¡Œ: fio --name=kafka-stress --directory={} --rw=randwrite --bs=4k --numjobs=8 --iodepth=64 --direct=1 --fsync=1", KAFKA_DATA_PATH);

            ProcessBuilder pb = new ProcessBuilder(cmd);
            pb.redirectErrorStream(true);
            fioProcess = pb.start();

            // å¯åŠ¨ä¸€ä¸ªçº¿ç¨‹è¯»å– fio è¾“å‡ºï¼ˆé¿å…é˜»å¡ï¼‰
            Thread outputReader = new Thread(() -> {
                try {
                    BufferedReader reader = new BufferedReader(new InputStreamReader(fioProcess.getInputStream()));
                    String line;
                    while ((line = reader.readLine()) != null) {
                        if (line.contains("IOPS") || line.contains("BW=")) {
                            logger.debug("fio: {}", line);
                        }
                    }
                } catch (Exception e) {
                    // ignore
                }
            });
            outputReader.setDaemon(true);
            outputReader.start();

            // ç­‰å¾… fio å¯åŠ¨
            Thread.sleep(2000);
            return fioProcess.isAlive();

        } catch (Exception e) {
            logger.error("å¯åŠ¨ fio å¤±è´¥: {}", e.getMessage());
            return false;
        }
    }

    private static void stopFioStress() {
        try {
            if (fioProcess != null && fioProcess.isAlive()) {
                fioProcess.destroy();
                fioProcess.waitFor(5, TimeUnit.SECONDS);
                if (fioProcess.isAlive()) {
                    fioProcess.destroyForcibly();
                }
            }

            // åŒæ—¶æ€æ­»æ‰€æœ‰ fio è¿›ç¨‹
            Runtime.getRuntime().exec(new String[]{"pkill", "-9", "fio"}).waitFor();

        } catch (Exception e) {
            logger.debug("åœæ­¢ fio å¼‚å¸¸: {}", e.getMessage());
        }
    }

    private static void cleanupFioFiles() {
        try {
            // åˆ é™¤ fio åˆ›å»ºçš„æµ‹è¯•æ–‡ä»¶
            String[] cmd = {"bash", "-c", "rm -f " + KAFKA_DATA_PATH + "/kafka-stress.*.0"};
            Runtime.getRuntime().exec(cmd).waitFor();
        } catch (Exception e) {
            logger.debug("æ¸…ç†æ–‡ä»¶å¼‚å¸¸: {}", e.getMessage());
        }
    }
}
