package com.example.kafka;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * æµ‹è¯•ç±»ï¼šä½¿ç”¨ Docker pause è§¦å‘ "batch creation" è¶…æ—¶
 *
 * ç­–ç•¥:
 *  - ä½¿ç”¨æ­£å¸¸çš„ topicï¼ˆä¸éœ€è¦ç‰¹æ®Šé…ç½®ï¼‰
 *  - å‘é€æ¶ˆæ¯åç«‹å³æš‚åœ Kafka broker
 *  - Broker æŒ‚èµ·ï¼ˆè¿›ç¨‹å†»ç»“ï¼‰ä½†è¿æ¥ä¸æ–­å¼€
 *  - ç­‰å¾… delivery.timeout.ms è¶…æ—¶
 *
 * ç›®æ ‡é”™è¯¯: "X ms has passed since batch creation"
 *
 * ä½¿ç”¨æ–¹æ³•:
 *  1. è¿è¡Œæ­¤ç¨‹åº
 *  2. çœ‹åˆ°æç¤ºåç«‹å³æ‰§è¡Œ: docker pause kafka-broker
 *  3. ç­‰å¾…30ç§’è¶…æ—¶
 *  4. å®Œæˆåæ‰§è¡Œ: docker unpause kafka-broker
 */
public class TestBatchCreationDockerPause {
    private static final Logger logger = LoggerFactory.getLogger(TestBatchCreationDockerPause.class);

    public static void main(String[] args) {
        logger.info("========== æµ‹è¯• Docker pause è§¦å‘ Batch Creation è¶…æ—¶ ==========\n");

        testDockerPause();

        logger.info("\n========== æµ‹è¯•å®Œæˆ ==========");
    }

    private static void testDockerPause() {
        logger.info("ã€æµ‹è¯•ã€‘Docker pause æ–¹æ¡ˆ");
        logger.info("ç­–ç•¥: å‘é€æ¶ˆæ¯åæš‚åœ Kafka broker\n");

        logger.warn("âš ï¸  å‡†å¤‡æ­¥éª¤:");
        logger.warn("   1. ç¡®ä¿ Kafka broker æ­£åœ¨è¿è¡Œ");
        logger.warn("   2. çœ‹åˆ°æç¤ºåç«‹å³æ‰§è¡Œ: docker pause kafka-broker");
        logger.warn("   3. æµ‹è¯•å®Œæˆåæ‰§è¡Œ: docker unpause kafka-broker\n");

        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");  // çœŸå® Kafka

        // å…³é”®é…ç½®
        props.put("acks", "1");  // æ­£å¸¸çš„ acks é…ç½®
        props.put("delivery.timeout.ms", "30000");  // 30ç§’è¶…æ—¶
        props.put("request.timeout.ms", "10000");
        props.put("linger.ms", "0");  // ç«‹å³å‘é€
        props.put("batch.size", "16384");
        props.put("retries", "3");
        props.put("retry.backoff.ms", "100");

        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());

        KafkaProducer<String, String> producer = null;
        final CountDownLatch latch = new CountDownLatch(5);
        final long startTime[] = {0};

        try {
            logger.info("1. åˆ›å»º KafkaProducer...");
            producer = new KafkaProducer<>(props);
            logger.info("   âœ… KafkaProducer åˆ›å»ºæˆåŠŸ\n");

            logger.info("2. å‘é€5æ¡æ¶ˆæ¯åˆ° test-topic...");

            startTime[0] = System.currentTimeMillis();

            for (int i = 1; i <= 5; i++) {
                final int msgNum = i;
                ProducerRecord<String, String> record =
                    new ProducerRecord<>("test-topic", "key-" + i, "value-" + i);

                producer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metadata, Exception exception) {
                        long elapsed = System.currentTimeMillis() - startTime[0];

                        if (exception != null) {
                            logger.error("\nâŒ æ¶ˆæ¯ #{} å‘é€å¤±è´¥ï¼è€—æ—¶: {}ms ({} ç§’)",
                                msgNum, elapsed, elapsed / 1000);
                            logger.error("å¼‚å¸¸ç±»å‹: {}", exception.getClass().getName());
                            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", exception.getMessage());

                            String message = exception.getMessage();
                            if (message != null) {
                                // æ£€æŸ¥å„ç§å¯èƒ½çš„ batch creation ç›¸å…³æ¶ˆæ¯
                                if (message.contains("batch creation") ||
                                    message.contains("since batch") ||
                                    message.contains("since last append")) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("Expiring") &&
                                          (message.contains("record") || message.contains("batch"))) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ è§¦å‘äº† Batch/Record è¿‡æœŸè¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… è¿™å¾ˆå¯èƒ½å°±æ˜¯ batch creation è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("ms") &&
                                          (message.contains("passed") || message.contains("elapsed"))) {
                                    logger.info("\nğŸ¯ è§¦å‘äº†æ—¶é—´ç›¸å…³çš„è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("timeout") || message.contains("Timeout")) {
                                    logger.info("\nâš ï¸  è§¦å‘äº†è¶…æ—¶å¼‚å¸¸");
                                    logger.info("   æ¶ˆæ¯: {}", message);
                                } else {
                                    logger.warn("\nâš ï¸  è§¦å‘äº†å…¶ä»–å¼‚å¸¸");
                                    logger.warn("   æ¶ˆæ¯: {}", message);
                                }
                            }

                            if (exception.getCause() != null) {
                                logger.error("æ ¹æœ¬åŸå› : {}", exception.getCause().getClass().getName());
                                logger.error("åŸå› æ¶ˆæ¯: {}", exception.getCause().getMessage());
                            }

                        } else {
                            logger.info("âœ… æ¶ˆæ¯ #{} å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                                msgNum, metadata.partition(), metadata.offset());
                        }

                        latch.countDown();
                    }
                });

                logger.info("   æ¶ˆæ¯ #{} å·²æäº¤", i);
            }

            logger.warn("\n");
            logger.warn("âš ï¸âš ï¸âš ï¸ ç«‹å³æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æš‚åœ Kafka broker:");
            logger.warn("   docker pause kafka-broker");
            logger.warn("\nç­‰å¾… delivery.timeout.ms=30ç§’ è¶…æ—¶...\n");

            // ç»™ç”¨æˆ·2ç§’æ—¶é—´æ‰§è¡Œ docker pause
            Thread.sleep(2000);
            logger.info("å‡è®¾ Kafka broker å·²è¢«æš‚åœï¼Œå¼€å§‹ç­‰å¾…è¶…æ—¶...\n");

            // ç­‰å¾…æ‰€æœ‰ Callback å®Œæˆï¼ˆæœ€å¤š 35 ç§’ï¼‰
            boolean completed = latch.await(35, TimeUnit.SECONDS);

            if (!completed) {
                logger.warn("âš ï¸  ç­‰å¾…è¶…æ—¶ï¼Œéƒ¨åˆ† Callback æœªæ‰§è¡Œ");
                logger.warn("   å¯èƒ½éœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´");
            }

        } catch (Exception e) {
            logger.error("\nå‘ç”Ÿå…¶ä»–å¼‚å¸¸: {}", e.getClass().getName());
            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", e.getMessage(), e);

        } finally {
            if (producer != null) {
                try {
                    logger.info("\n3. å…³é—­ KafkaProducer...");
                    producer.close();
                    logger.info("   KafkaProducer å·²å…³é—­\n");
                } catch (Exception e) {
                    logger.debug("å…³é—­ producer æ—¶å‘ç”Ÿå¼‚å¸¸", e);
                }
            }

            logger.warn("\nâš ï¸  è®°å¾—æ¢å¤ Kafka broker:");
            logger.warn("   docker unpause kafka-broker\n");
        }
    }
}