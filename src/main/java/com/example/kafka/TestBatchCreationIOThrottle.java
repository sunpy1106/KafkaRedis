package com.example.kafka;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.io.*;
import java.nio.file.*;
import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * æµ‹è¯•ç±»ï¼šä½¿ç”¨ cgroup I/O é™é€Ÿè§¦å‘ "batch creation" è¶…æ—¶
 *
 * åŸç†:
 *  - ä½¿ç”¨ cgroup v2 çš„ io.max é™åˆ¶ Kafka å®¹å™¨çš„ç£ç›˜å†™å…¥é€Ÿåº¦
 *  - æä½çš„å†™å…¥é€Ÿåº¦ (å¦‚ 1KB/s) ä¼šå¯¼è‡´ fsync é˜»å¡
 *  - æ¶ˆæ¯åœ¨ batch ä¸­ç­‰å¾…è¶…è¿‡ delivery.timeout.ms åè¶…æ—¶
 *
 * ç›®æ ‡é”™è¯¯: "X ms has passed since batch creation"
 *
 * ä½¿ç”¨æ–¹æ³•:
 *   sudo mvn exec:java -Dexec.mainClass="com.example.kafka.TestBatchCreationIOThrottle"
 *
 * æ³¨æ„: éœ€è¦ root æƒé™æ¥ä¿®æ”¹ cgroup è®¾ç½®
 */
public class TestBatchCreationIOThrottle {
    private static final Logger logger = LoggerFactory.getLogger(TestBatchCreationIOThrottle.class);

    private static final String BOOTSTRAP_SERVERS = "localhost:19092";
    private static final String TOPIC = "test-topic";
    private static final String CONTAINER_NAME = "kafka-broker";

    // è®¾å¤‡å· (sda = 8:0)
    private static final String DEVICE_MAJOR_MINOR = "8:0";

    // I/O é™é€Ÿ: 1KB/s å†™å…¥é€Ÿåº¦ (ææ…¢)
    private static final long WRITE_BPS_LIMIT = 1024;  // 1 KB/s

    // è¶…æ—¶é…ç½®
    private static final int DELIVERY_TIMEOUT_MS = 30000;  // 30ç§’
    private static final int REQUEST_TIMEOUT_MS = 10000;   // 10ç§’

    public static void main(String[] args) {
        logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
        logger.info("â•‘   Cgroup I/O é™é€Ÿæ–¹æ³•è§¦å‘ Batch Creation è¶…æ—¶                  â•‘");
        logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n");

        // æ£€æŸ¥æ˜¯å¦æœ‰ root æƒé™
        if (!checkRootPrivilege()) {
            logger.error("âŒ éœ€è¦ root æƒé™æ¥ä¿®æ”¹ cgroup è®¾ç½®");
            logger.error("   è¯·ä½¿ç”¨: sudo mvn exec:java -Dexec.mainClass=\"com.example.kafka.TestBatchCreationIOThrottle\"");
            return;
        }

        runTest();

        logger.info("\n========== æµ‹è¯•å®Œæˆ ==========");
    }

    private static void runTest() {
        String cgroupPath = findCgroupPath();
        if (cgroupPath == null) {
            logger.error("âŒ æ— æ³•æ‰¾åˆ° Kafka å®¹å™¨çš„ cgroup è·¯å¾„");
            return;
        }

        logger.info("æ‰¾åˆ° cgroup è·¯å¾„: {}", cgroupPath);
        String ioMaxPath = cgroupPath + "/io.max";

        KafkaProducer<String, String> producer = null;
        final AtomicBoolean ioLimited = new AtomicBoolean(false);
        final CountDownLatch warmupLatch = new CountDownLatch(1);
        final CountDownLatch testLatch = new CountDownLatch(10);
        final long[] startTime = {0};
        final AtomicInteger successCount = new AtomicInteger(0);
        final AtomicInteger failureCount = new AtomicInteger(0);
        final AtomicBoolean targetErrorTriggered = new AtomicBoolean(false);

        try {
            // 1. åˆ›å»º Producer
            Properties props = new Properties();
            props.put("bootstrap.servers", BOOTSTRAP_SERVERS);
            props.put("key.serializer", StringSerializer.class.getName());
            props.put("value.serializer", StringSerializer.class.getName());
            props.put("acks", "all");
            props.put("delivery.timeout.ms", String.valueOf(DELIVERY_TIMEOUT_MS));
            props.put("request.timeout.ms", String.valueOf(REQUEST_TIMEOUT_MS));
            props.put("max.block.ms", "10000");
            props.put("linger.ms", "500");
            props.put("batch.size", "16384");
            props.put("retries", "3");
            props.put("retry.backoff.ms", "1000");

            logger.info("1. åˆ›å»º KafkaProducer...");
            producer = new KafkaProducer<>(props);
            logger.info("   âœ… KafkaProducer åˆ›å»ºæˆåŠŸ\n");

            // 2. å‘é€é¢„çƒ­æ¶ˆæ¯
            logger.info("2. å‘é€é¢„çƒ­æ¶ˆæ¯ï¼ˆç¼“å­˜ metadataï¼‰...");
            producer.send(
                new ProducerRecord<>(TOPIC, "warmup", "warmup-" + System.currentTimeMillis()),
                (metadata, exception) -> {
                    if (exception != null) {
                        logger.error("   âŒ é¢„çƒ­å¤±è´¥: {}", exception.getMessage());
                    } else {
                        logger.info("   âœ… é¢„çƒ­æˆåŠŸ - Partition: {}, Offset: {}",
                            metadata.partition(), metadata.offset());
                    }
                    warmupLatch.countDown();
                }
            );

            if (!warmupLatch.await(15, TimeUnit.SECONDS)) {
                logger.error("   âŒ é¢„çƒ­è¶…æ—¶");
                return;
            }
            producer.flush();
            logger.info("   âœ… Metadata å·²ç¼“å­˜\n");

            Thread.sleep(2000);

            // 3. è®¾ç½® I/O é™é€Ÿ
            logger.info("3. è®¾ç½® I/O é™é€Ÿ (å†™å…¥é€Ÿåº¦: {} bytes/s)...", WRITE_BPS_LIMIT);
            if (setIOLimit(ioMaxPath, WRITE_BPS_LIMIT)) {
                ioLimited.set(true);
                logger.info("   âœ… I/O é™é€Ÿå·²è®¾ç½®");
                logger.info("   ğŸ“‹ å½“å‰é™åˆ¶: {} wbps={}", DEVICE_MAJOR_MINOR, WRITE_BPS_LIMIT);

                // æ˜¾ç¤ºå½“å‰è®¾ç½®
                String currentLimit = readFile(ioMaxPath);
                logger.info("   ğŸ“‹ io.max å†…å®¹: {}\n", currentLimit.trim());
            } else {
                logger.error("   âŒ è®¾ç½® I/O é™é€Ÿå¤±è´¥");
                return;
            }

            // ç­‰å¾…é™é€Ÿç”Ÿæ•ˆ
            Thread.sleep(3000);

            // 4. å‘é€æµ‹è¯•æ¶ˆæ¯
            logger.info("4. å‘é€ 10 æ¡æµ‹è¯•æ¶ˆæ¯...");
            logger.info("   â””â”€ æä½çš„ I/O é€Ÿåº¦ä¼šå¯¼è‡´ fsync é˜»å¡");
            logger.info("   â””â”€ ç­‰å¾… delivery.timeout.ms={} ç§’åè¶…æ—¶\n", DELIVERY_TIMEOUT_MS / 1000);

            startTime[0] = System.currentTimeMillis();

            for (int i = 1; i <= 10; i++) {
                final int msgNum = i;
                // å‘é€è¾ƒå¤§çš„æ¶ˆæ¯ä»¥å¢åŠ  I/O å‹åŠ›
                String largeValue = generateLargeMessage(1024);  // 1KB æ¶ˆæ¯
                ProducerRecord<String, String> record = new ProducerRecord<>(
                    TOPIC, "key-" + i, largeValue
                );

                producer.send(record, (metadata, exception) -> {
                    long elapsed = System.currentTimeMillis() - startTime[0];

                    if (exception != null) {
                        failureCount.incrementAndGet();
                        String errMsg = exception.getMessage();

                        logger.error("\nâ•”â•â•â•â• æ¶ˆæ¯ #{} å‘é€å¤±è´¥ â•â•â•â•â•—", msgNum);
                        logger.error("â•‘ è€—æ—¶: {}ms ({:.1f}ç§’)", elapsed, elapsed / 1000.0);
                        logger.error("â•‘ ç±»å‹: {}", exception.getClass().getSimpleName());
                        logger.error("â•‘ æ¶ˆæ¯: {}", errMsg);

                        if (errMsg != null && (errMsg.contains("batch creation") ||
                            errMsg.contains("since batch") ||
                            errMsg.contains("Expiring"))) {
                            targetErrorTriggered.set(true);
                            logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
                            logger.info("â•‘ ğŸ¯ğŸ¯ğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼  â•‘");
                            logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
                        }
                        logger.error("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
                    } else {
                        successCount.incrementAndGet();
                        logger.info("   âœ… æ¶ˆæ¯ #{} æˆåŠŸ ({}ms)", msgNum, elapsed);
                    }

                    testLatch.countDown();
                });

                logger.info("   â””â”€ å·²æäº¤æ¶ˆæ¯ #{}", i);
            }

            // 5. ç­‰å¾…è¶…æ—¶
            logger.info("\n5. ç­‰å¾…æ¶ˆæ¯å¤„ç†...");

            Thread countdown = new Thread(() -> {
                int totalSeconds = DELIVERY_TIMEOUT_MS / 1000 + 15;
                for (int i = totalSeconds; i > 0; i--) {
                    if (testLatch.getCount() == 0) break;
                    if (i % 10 == 0 || i <= 5) {
                        logger.info("   â± å‰©ä½™ {} ç§’ | æˆåŠŸ: {} | å¤±è´¥: {}",
                            i, successCount.get(), failureCount.get());
                    }
                    try { Thread.sleep(1000); } catch (InterruptedException e) { break; }
                }
            });
            countdown.setDaemon(true);
            countdown.start();

            boolean completed = testLatch.await(DELIVERY_TIMEOUT_MS + 20000, TimeUnit.MILLISECONDS);

            // 6. è¾“å‡ºç»“æœ
            logger.info("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
            logger.info("â•‘           æµ‹è¯•ç»“æœæ±‡æ€»                â•‘");
            logger.info("â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£");
            logger.info("â•‘ æˆåŠŸå‘é€:    {:2}                      â•‘", successCount.get());
            logger.info("â•‘ å‘é€å¤±è´¥:    {:2}                      â•‘", failureCount.get());
            logger.info("â•‘ ç›®æ ‡é”™è¯¯:    {}                     â•‘", targetErrorTriggered.get() ? "âœ…" : "âŒ");
            logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");

            if (targetErrorTriggered.get()) {
                logger.info("\nğŸ‰ ä½¿ç”¨ I/O é™é€ŸæˆåŠŸå¤ç° Batch Creation è¶…æ—¶ï¼");
            }

        } catch (Exception e) {
            logger.error("æµ‹è¯•å¼‚å¸¸: {}", e.getMessage(), e);
        } finally {
            // 7. æ¸…ç† I/O é™é€Ÿ
            if (ioLimited.get()) {
                logger.info("\n6. æ¸…ç† I/O é™é€Ÿ...");
                if (clearIOLimit(ioMaxPath)) {
                    logger.info("   âœ… I/O é™é€Ÿå·²æ¸…ç†");
                } else {
                    logger.warn("   âš ï¸ æ¸…ç†å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ:");
                    logger.warn("   echo '' > {}", ioMaxPath);
                }
            }

            if (producer != null) {
                logger.info("\n7. å…³é—­ KafkaProducer...");
                try {
                    producer.close(5, TimeUnit.SECONDS);
                    logger.info("   âœ… å·²å…³é—­");
                } catch (Exception e) {
                    logger.debug("å…³é—­å¼‚å¸¸", e);
                }
            }
        }
    }

    private static boolean checkRootPrivilege() {
        try {
            Process p = Runtime.getRuntime().exec(new String[]{"id", "-u"});
            BufferedReader reader = new BufferedReader(new InputStreamReader(p.getInputStream()));
            String uid = reader.readLine();
            return "0".equals(uid);
        } catch (Exception e) {
            return false;
        }
    }

    private static String findCgroupPath() {
        try {
            // è·å–å®¹å™¨ ID
            Process p = Runtime.getRuntime().exec(new String[]{
                "docker", "inspect", CONTAINER_NAME, "--format", "{{.Id}}"
            });
            BufferedReader reader = new BufferedReader(new InputStreamReader(p.getInputStream()));
            String containerId = reader.readLine();
            if (containerId == null || containerId.isEmpty()) {
                return null;
            }

            // æŸ¥æ‰¾ cgroup è·¯å¾„
            String basePath = "/sys/fs/cgroup/system.slice";
            File dir = new File(basePath);
            if (dir.exists() && dir.isDirectory()) {
                for (File f : dir.listFiles()) {
                    if (f.getName().contains(containerId.substring(0, 12))) {
                        return f.getAbsolutePath();
                    }
                }
            }

            // å°è¯•å…¶ä»–è·¯å¾„
            Process findP = Runtime.getRuntime().exec(new String[]{
                "find", "/sys/fs/cgroup", "-name", "*" + containerId.substring(0, 12) + "*", "-type", "d"
            });
            BufferedReader findReader = new BufferedReader(new InputStreamReader(findP.getInputStream()));
            return findReader.readLine();

        } catch (Exception e) {
            logger.error("æŸ¥æ‰¾ cgroup è·¯å¾„å¤±è´¥: {}", e.getMessage());
            return null;
        }
    }

    private static boolean setIOLimit(String ioMaxPath, long writeBps) {
        try {
            String limit = DEVICE_MAJOR_MINOR + " wbps=" + writeBps;
            Files.write(Paths.get(ioMaxPath), limit.getBytes());
            return true;
        } catch (Exception e) {
            logger.error("è®¾ç½® I/O é™é€Ÿå¤±è´¥: {}", e.getMessage());
            return false;
        }
    }

    private static boolean clearIOLimit(String ioMaxPath) {
        try {
            Files.write(Paths.get(ioMaxPath), "".getBytes());
            return true;
        } catch (Exception e) {
            logger.error("æ¸…ç† I/O é™é€Ÿå¤±è´¥: {}", e.getMessage());
            return false;
        }
    }

    private static String readFile(String path) {
        try {
            return new String(Files.readAllBytes(Paths.get(path)));
        } catch (Exception e) {
            return "æ— æ³•è¯»å–";
        }
    }

    private static String generateLargeMessage(int size) {
        StringBuilder sb = new StringBuilder(size);
        for (int i = 0; i < size; i++) {
            sb.append((char) ('a' + (i % 26)));
        }
        return sb.toString();
    }
}
