package com.example.kafka;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.atomic.AtomicInteger;

/**
 * æµ‹è¯•ç±»ï¼šé€šè¿‡ç£ç›˜I/Oç¹å¿™è§¦å‘ "batch creation" è¶…æ—¶
 *
 * ç­–ç•¥:
 *  - Kafka æ­£å¸¸è¿è¡Œ
 *  - å‘é€é¢„çƒ­æ¶ˆæ¯ï¼ˆç¼“å­˜ metadataï¼‰
 *  - å¯åŠ¨å¤§é‡ddè¿›ç¨‹åˆ¶é€ æå¤§çš„ç£ç›˜I/Oå‹åŠ›
 *  - å‘é€æµ‹è¯•æ¶ˆæ¯
 *  - Brokerçš„fsyncæ“ä½œè¢«é˜»å¡ï¼Œæ— æ³•åŠæ—¶è¿”å›ç¡®è®¤
 *  - ç­‰å¾… delivery.timeout.ms è¶…æ—¶
 *
 * ç›®æ ‡é”™è¯¯: "X ms has passed since batch creation"
 *
 * å…³é”®åŒºåˆ«ï¼š
 *  - ç£ç›˜æ»¡ï¼šfsyncä»ç„¶å¿«ï¼ˆé¢„åˆ†é…ç©ºé—´å†…ï¼‰
 *  - ç£ç›˜ç¹å¿™ï¼šfsyncçœŸæ­£é˜»å¡åœ¨å†…æ ¸I/Oæ“ä½œä¸Š
 *
 * ä½¿ç”¨æ–¹æ³•:
 *  1. è¿è¡Œæ­¤ç¨‹åº
 *  2. çœ‹åˆ°æç¤ºååœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡ŒI/Oå‹åŠ›å‘½ä»¤
 *  3. ç­‰å¾…è¶…æ—¶
 *  4. æ¸…ç†ddè¿›ç¨‹å’Œæ–‡ä»¶
 */
public class TestBatchCreationDiskBusy {
    private static final Logger logger = LoggerFactory.getLogger(TestBatchCreationDiskBusy.class);

    public static void main(String[] args) {
        logger.info("========== æµ‹è¯•ç£ç›˜I/Oç¹å¿™è§¦å‘ Batch Creation è¶…æ—¶ ==========\n");

        testDiskBusy();

        logger.info("\n========== æµ‹è¯•å®Œæˆ ==========");
    }

    private static void testDiskBusy() {
        logger.info("ã€æµ‹è¯•ã€‘ç£ç›˜I/Oç¹å¿™æ–¹æ¡ˆ");
        logger.info("ç­–ç•¥: åˆ¶é€ æå¤§ç£ç›˜I/Oå‹åŠ›ï¼Œé˜»å¡Brokerçš„fsyncæ“ä½œ\n");

        logger.warn("âš ï¸  å‡†å¤‡æ­¥éª¤:");
        logger.warn("   1. ç¡®ä¿ Kafka broker æ­£åœ¨è¿è¡Œ");
        logger.warn("   2. å‡†å¤‡åœ¨çœ‹åˆ°æç¤ºåæ‰§è¡ŒI/Oå‹åŠ›å‘½ä»¤");
        logger.warn("   3. æµ‹è¯•å®Œæˆåè®°å¾—æ¸…ç†è¿›ç¨‹å’Œæ–‡ä»¶\n");

        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");  // çœŸå® Kafka

        // ä¼˜åŒ–é…ç½®ä»¥å¢åŠ è§¦å‘æ¦‚ç‡
        props.put("acks", "all");  // éœ€è¦æ‰€æœ‰ISRç¡®è®¤ï¼ˆæ›´ä¸¥æ ¼ï¼‰
        props.put("delivery.timeout.ms", "40000");  // 40ç§’è¶…æ—¶
        props.put("request.timeout.ms", "15000");   // 15ç§’è¯·æ±‚è¶…æ—¶
        props.put("linger.ms", "100");  // 100mså»¶è¿Ÿï¼Œè®©æ¶ˆæ¯ç§¯ç´¯
        props.put("batch.size", "1024");  // å°batch sizeï¼Œå®¹æ˜“å¡«æ»¡
        props.put("retries", "3");
        props.put("retry.backoff.ms", "100");

        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());

        KafkaProducer<String, String> producer = null;
        final CountDownLatch warmupLatch = new CountDownLatch(1);
        final CountDownLatch testLatch = new CountDownLatch(100);  // 100æ¡æ¶ˆæ¯
        final long startTime[] = {0};
        final AtomicInteger successCount = new AtomicInteger(0);
        final AtomicInteger failureCount = new AtomicInteger(0);

        try {
            logger.info("1. åˆ›å»º KafkaProducer...");
            producer = new KafkaProducer<>(props);
            logger.info("   âœ… KafkaProducer åˆ›å»ºæˆåŠŸ");
            logger.info("   é…ç½®: acks=all, delivery.timeout=40s, request.timeout=15s\n");

            logger.info("2. å‘é€é¢„çƒ­æ¶ˆæ¯ï¼ˆç¼“å­˜ metadataï¼‰...");
            ProducerRecord<String, String> warmupRecord =
                new ProducerRecord<>("test-topic", "warmup-key", "warmup-value");

            producer.send(warmupRecord, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception != null) {
                        logger.error("é¢„çƒ­æ¶ˆæ¯å‘é€å¤±è´¥: {}", exception.getMessage());
                    } else {
                        logger.info("   âœ… é¢„çƒ­æ¶ˆæ¯å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                            metadata.partition(), metadata.offset());
                        logger.info("   âœ… Metadata å·²ç¼“å­˜\n");
                    }
                    warmupLatch.countDown();
                }
            });

            // ç­‰å¾…é¢„çƒ­å®Œæˆ
            if (!warmupLatch.await(10, TimeUnit.SECONDS)) {
                logger.error("é¢„çƒ­æ¶ˆæ¯å‘é€è¶…æ—¶");
                return;
            }

            logger.warn("\n");
            logger.warn("âš ï¸âš ï¸âš ï¸ å…³é”®æ­¥éª¤ - è¯·åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤:");
            logger.warn("");
            logger.warn("# å¯åŠ¨20ä¸ªddè¿›ç¨‹åˆ¶é€ æå¤§I/Oå‹åŠ›");
            logger.warn("for i in {{1..20}}; do");
            logger.warn("  docker exec -d kafka-broker dd if=/dev/zero \\");
            logger.warn("    of=/kafka/kafka-logs-kafka/stress_$i.dat \\");
            logger.warn("    bs=4M count=2000 oflag=sync 2>/dev/null &");
            logger.warn("done");
            logger.warn("");
            logger.warn("# éªŒè¯I/Oå‹åŠ›ï¼ˆå¯é€‰ï¼‰");
            logger.warn("docker exec kafka-broker ps aux | grep -c dd");
            logger.warn("");
            logger.warn("â° è¯·åœ¨ 15 ç§’å†…å¯åŠ¨I/Oå‹åŠ›...\n");

            // ç­‰å¾…ç”¨æˆ·å¯åŠ¨I/Oå‹åŠ›
            Thread.sleep(15000);

            logger.info("3. ç­‰å¾…5ç§’ï¼Œè®©I/Oå‹åŠ›å……åˆ†ç”Ÿæ•ˆ...\n");
            Thread.sleep(5000);

            logger.info("4. å‘é€100æ¡æµ‹è¯•æ¶ˆæ¯ï¼ˆå¢åŠ è§¦å‘flushçš„æ¦‚ç‡ï¼‰...");
            logger.info("   æ­¤æ—¶ç£ç›˜I/Oåº”è¯¥æåº¦ç¹å¿™");
            logger.info("   Brokerçš„fsyncæ“ä½œåº”è¯¥è¢«ä¸¥é‡é˜»å¡\n");

            startTime[0] = System.currentTimeMillis();

            // å‘é€100æ¡æ¶ˆæ¯
            for (int i = 1; i <= 100; i++) {
                final int msgNum = i;
                ProducerRecord<String, String> record =
                    new ProducerRecord<>("test-topic", "key-" + i, "value-" + i);

                producer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metadata, Exception exception) {
                        long elapsed = System.currentTimeMillis() - startTime[0];

                        if (exception != null) {
                            failureCount.incrementAndGet();
                            logger.error("\nâŒ æ¶ˆæ¯ #{} å‘é€å¤±è´¥ï¼è€—æ—¶: {}ms ({} ç§’)",
                                msgNum, elapsed, elapsed / 1000);
                            logger.error("å¼‚å¸¸ç±»å‹: {}", exception.getClass().getName());
                            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", exception.getMessage());

                            String message = exception.getMessage();
                            if (message != null) {
                                // æ£€æŸ¥å„ç§å¯èƒ½çš„ batch creation ç›¸å…³æ¶ˆæ¯
                                if (message.contains("batch creation") ||
                                    message.contains("since batch") ||
                                    message.contains("since last append")) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("Expiring") &&
                                          (message.contains("record") || message.contains("batch"))) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ è§¦å‘äº† Batch/Record è¿‡æœŸè¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… è¿™å¾ˆå¯èƒ½å°±æ˜¯ batch creation è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("ms") &&
                                          (message.contains("passed") || message.contains("elapsed"))) {
                                    logger.info("\nğŸ¯ è§¦å‘äº†æ—¶é—´ç›¸å…³çš„è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("40") && message.contains("ms")) {
                                    logger.info("\nğŸ¯ è§¦å‘äº†40ç§’è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("timeout") || message.contains("Timeout")) {
                                    logger.info("\nâš ï¸  è§¦å‘äº†è¶…æ—¶å¼‚å¸¸");
                                    logger.info("   æ¶ˆæ¯: {}", message);
                                } else {
                                    logger.warn("\nâš ï¸  è§¦å‘äº†å…¶ä»–å¼‚å¸¸");
                                    logger.warn("   æ¶ˆæ¯: {}", message);
                                }
                            }

                            if (exception.getCause() != null) {
                                logger.error("æ ¹æœ¬åŸå› : {}", exception.getCause().getClass().getName());
                                logger.error("åŸå› æ¶ˆæ¯: {}", exception.getCause().getMessage());
                            }

                        } else {
                            successCount.incrementAndGet();
                            if (msgNum % 20 == 0) {
                                logger.info("âœ… æ¶ˆæ¯ #{} å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                                    msgNum, metadata.partition(), metadata.offset());
                            }
                        }

                        testLatch.countDown();
                    }
                });

                if (i % 20 == 0) {
                    logger.info("   å·²æäº¤ {} æ¡æ¶ˆæ¯...", i);
                }
            }

            logger.warn("\nç­‰å¾… delivery.timeout.ms=40ç§’ è¶…æ—¶...");
            logger.warn("ï¼ˆå¦‚æœç£ç›˜I/Oæåº¦ç¹å¿™ï¼ŒBroker fsyncé˜»å¡ï¼Œåº”è¯¥ä¼šè¶…æ—¶ï¼‰\n");

            // å¯åŠ¨å€’è®¡æ—¶çº¿ç¨‹
            Thread countdownThread = new Thread(() -> {
                for (int i = 40; i > 0; i--) {
                    if (i % 10 == 0 || i <= 5) {
                        logger.info("   è¿˜éœ€ç­‰å¾…: {} ç§’... (æˆåŠŸ:{}, å¤±è´¥:{})",
                            i, successCount.get(), failureCount.get());
                    }
                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                        break;
                    }
                    if (testLatch.getCount() == 0) {
                        logger.info("   æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæ¯•");
                        break;
                    }
                }
            });
            countdownThread.setDaemon(true);
            countdownThread.start();

            // ç­‰å¾…æ‰€æœ‰ Callback å®Œæˆï¼ˆæœ€å¤š 45 ç§’ï¼‰
            boolean completed = testLatch.await(45, TimeUnit.SECONDS);

            logger.info("\n========== æµ‹è¯•ç»“æœ ==========");
            logger.info("æˆåŠŸå‘é€: {} æ¡", successCount.get());
            logger.info("å‘é€å¤±è´¥: {} æ¡", failureCount.get());
            logger.info("å¤„ç†å®Œæˆ: {}", completed ? "æ˜¯" : "å¦ï¼ˆéƒ¨åˆ†è¶…æ—¶ï¼‰");
            logger.info("==============================\n");

            if (!completed) {
                logger.warn("âš ï¸  ç­‰å¾…è¶…æ—¶ï¼Œéƒ¨åˆ† Callback æœªæ‰§è¡Œ");
                logger.warn("   å¯èƒ½éœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´");
            }

        } catch (Exception e) {
            logger.error("\nå‘ç”Ÿå…¶ä»–å¼‚å¸¸: {}", e.getClass().getName());
            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", e.getMessage(), e);

        } finally {
            if (producer != null) {
                try {
                    logger.info("\n5. å…³é—­ KafkaProducer...");
                    producer.close(5, TimeUnit.SECONDS);
                    logger.info("   KafkaProducer å·²å…³é—­\n");
                } catch (Exception e) {
                    logger.debug("å…³é—­ producer æ—¶å‘ç”Ÿå¼‚å¸¸", e);
                }
            }

            logger.warn("\nâš ï¸  è®°å¾—æ¸…ç†I/Oå‹åŠ›:");
            logger.warn("   # åœæ­¢æ‰€æœ‰ddè¿›ç¨‹");
            logger.warn("   docker exec kafka-broker pkill dd");
            logger.warn("");
            logger.warn("   # åˆ é™¤å‹åŠ›æ–‡ä»¶");
            logger.warn("   docker exec kafka-broker rm -f /kafka/kafka-logs-kafka/stress_*.dat");
            logger.warn("");
            logger.warn("   # éªŒè¯æ¸…ç†");
            logger.warn("   docker exec kafka-broker df -h /kafka\n");
        }
    }
}
