package com.example.kafka;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * æµ‹è¯•ç±»ï¼šé€šè¿‡å¡«æ»¡ç£ç›˜è§¦å‘ "batch creation" è¶…æ—¶
 *
 * ç­–ç•¥:
 *  - Kafka æ­£å¸¸è¿è¡Œ
 *  - å‘é€é¢„çƒ­æ¶ˆæ¯ï¼ˆç¼“å­˜ metadataï¼‰
 *  - åœ¨ Kafka æ•°æ®ç›®å½•å¡«æ»¡ç£ç›˜
 *  - å‘é€æµ‹è¯•æ¶ˆæ¯
 *  - Broker æ— æ³•å†™å…¥ç£ç›˜ï¼Œæ— æ³•è¿”å›ç¡®è®¤
 *  - ç­‰å¾… delivery.timeout.ms è¶…æ—¶
 *
 * ç›®æ ‡é”™è¯¯: "X ms has passed since batch creation"
 *
 * ä½¿ç”¨æ–¹æ³•:
 *  1. è¿è¡Œæ­¤ç¨‹åº
 *  2. çœ‹åˆ°æç¤ºååœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œ:
 *     docker exec kafka-broker dd if=/dev/zero of=/tmp/kafka-logs/fillup.dat bs=1M count=10000
 *  3. ç­‰å¾…è¶…æ—¶
 *  4. æ¸…ç†: docker exec kafka-broker rm /tmp/kafka-logs/fillup.dat
 */
public class TestBatchCreationDiskFull {
    private static final Logger logger = LoggerFactory.getLogger(TestBatchCreationDiskFull.class);

    public static void main(String[] args) {
        logger.info("========== æµ‹è¯•ç£ç›˜å¡«æ»¡è§¦å‘ Batch Creation è¶…æ—¶ ==========\n");

        testDiskFull();

        logger.info("\n========== æµ‹è¯•å®Œæˆ ==========");
    }

    private static void testDiskFull() {
        logger.info("ã€æµ‹è¯•ã€‘ç£ç›˜å¡«æ»¡æ–¹æ¡ˆ");
        logger.info("ç­–ç•¥: å¡«æ»¡ Kafka æ•°æ®ç›®å½•ï¼Œå¯¼è‡´ Broker æ— æ³•å†™å…¥\n");

        logger.warn("âš ï¸  å‡†å¤‡æ­¥éª¤:");
        logger.warn("   1. ç¡®ä¿ Kafka broker æ­£åœ¨è¿è¡Œ");
        logger.warn("   2. å‡†å¤‡åœ¨çœ‹åˆ°æç¤ºåæ‰§è¡Œå‘½ä»¤å¡«æ»¡ç£ç›˜");
        logger.warn("   3. æµ‹è¯•å®Œæˆåè®°å¾—æ¸…ç†ç£ç›˜ç©ºé—´\n");

        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");  // çœŸå® Kafka

        // å…³é”®é…ç½®
        props.put("acks", "1");  // Broker å¿…é¡»å†™å…¥ç£ç›˜æ‰ç¡®è®¤
        props.put("delivery.timeout.ms", "30000");  // 30ç§’è¶…æ—¶
        props.put("request.timeout.ms", "10000");
        props.put("linger.ms", "1000");  // ç¨å¾®å»¶è¿Ÿ
        props.put("batch.size", "16384");
        props.put("retries", "3");
        props.put("retry.backoff.ms", "100");

        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());

        KafkaProducer<String, String> producer = null;
        final CountDownLatch warmupLatch = new CountDownLatch(1);
        final CountDownLatch testLatch = new CountDownLatch(10);
        final long startTime[] = {0};

        try {
            logger.info("1. åˆ›å»º KafkaProducer...");
            producer = new KafkaProducer<>(props);
            logger.info("   âœ… KafkaProducer åˆ›å»ºæˆåŠŸ\n");

            logger.info("2. å‘é€é¢„çƒ­æ¶ˆæ¯ï¼ˆç¼“å­˜ metadataï¼‰...");
            ProducerRecord<String, String> warmupRecord =
                new ProducerRecord<>("test-topic", "warmup-key", "warmup-value");

            producer.send(warmupRecord, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    if (exception != null) {
                        logger.error("é¢„çƒ­æ¶ˆæ¯å‘é€å¤±è´¥: {}", exception.getMessage());
                    } else {
                        logger.info("   âœ… é¢„çƒ­æ¶ˆæ¯å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                            metadata.partition(), metadata.offset());
                        logger.info("   âœ… Metadata å·²ç¼“å­˜\n");
                    }
                    warmupLatch.countDown();
                }
            });

            // ç­‰å¾…é¢„çƒ­å®Œæˆ
            if (!warmupLatch.await(10, TimeUnit.SECONDS)) {
                logger.error("é¢„çƒ­æ¶ˆæ¯å‘é€è¶…æ—¶");
                return;
            }

            logger.warn("\n");
            logger.warn("âš ï¸âš ï¸âš ï¸ å…³é”®æ­¥éª¤ - è¯·åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œ:");
            logger.warn("   # æŸ¥çœ‹ Kafka æ•°æ®ç›®å½•");
            logger.warn("   docker exec kafka-broker df -h /kafka");
            logger.warn("");
            logger.warn("   # å¡«æ»¡ç£ç›˜ï¼ˆåˆ›å»ºå¤§æ–‡ä»¶ - å¡«æ»¡å‰©ä½™ 30Gï¼‰");
            logger.warn("   docker exec kafka-broker dd if=/dev/zero of=/kafka/kafka-logs-kafka/fillup.dat bs=1M count=30000");
            logger.warn("");
            logger.warn("   # æˆ–è€…æ›´æ¿€è¿›ï¼šå¡«æ»¡æ‰€æœ‰å¯ç”¨ç©ºé—´");
            logger.warn("   docker exec kafka-broker sh -c 'dd if=/dev/zero of=/kafka/kafka-logs-kafka/fillup.dat bs=1M || true'");
            logger.warn("");
            logger.warn("â° è¯·åœ¨ 10 ç§’å†…æ‰§è¡Œå¡«æ»¡ç£ç›˜å‘½ä»¤...\n");

            // ç­‰å¾…ç”¨æˆ·å¡«æ»¡ç£ç›˜
            Thread.sleep(10000);

            logger.info("3. å‘é€10æ¡æµ‹è¯•æ¶ˆæ¯...");
            logger.info("   ï¼ˆBroker åº”è¯¥æ— æ³•å†™å…¥ç£ç›˜ï¼‰\n");

            startTime[0] = System.currentTimeMillis();

            // å‘é€10æ¡æ¶ˆæ¯
            for (int i = 1; i <= 10; i++) {
                final int msgNum = i;
                ProducerRecord<String, String> record =
                    new ProducerRecord<>("test-topic", "key-" + i, "value-" + i);

                producer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metadata, Exception exception) {
                        long elapsed = System.currentTimeMillis() - startTime[0];

                        if (exception != null) {
                            logger.error("\nâŒ æ¶ˆæ¯ #{} å‘é€å¤±è´¥ï¼è€—æ—¶: {}ms ({} ç§’)",
                                msgNum, elapsed, elapsed / 1000);
                            logger.error("å¼‚å¸¸ç±»å‹: {}", exception.getClass().getName());
                            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", exception.getMessage());

                            String message = exception.getMessage();
                            if (message != null) {
                                // æ£€æŸ¥å„ç§å¯èƒ½çš„ batch creation ç›¸å…³æ¶ˆæ¯
                                if (message.contains("batch creation") ||
                                    message.contains("since batch") ||
                                    message.contains("since last append")) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("Expiring") &&
                                          (message.contains("record") || message.contains("batch"))) {
                                    logger.info("\nğŸ¯ğŸ¯ğŸ¯ è§¦å‘äº† Batch/Record è¿‡æœŸè¶…æ—¶ï¼ğŸ¯ğŸ¯ğŸ¯");
                                    logger.info("âœ…âœ…âœ… è¿™å¾ˆå¯èƒ½å°±æ˜¯ batch creation è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("ms") &&
                                          (message.contains("passed") || message.contains("elapsed"))) {
                                    logger.info("\nğŸ¯ è§¦å‘äº†æ—¶é—´ç›¸å…³çš„è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("30") && message.contains("ms")) {
                                    logger.info("\nğŸ¯ è§¦å‘äº†30ç§’è¶…æ—¶ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("disk") || message.contains("space") ||
                                          message.contains("full") || message.contains("quota")) {
                                    logger.info("\nğŸ¯ è§¦å‘äº†ç£ç›˜ç›¸å…³é”™è¯¯ï¼");
                                    logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                                } else if (message.contains("timeout") || message.contains("Timeout")) {
                                    logger.info("\nâš ï¸  è§¦å‘äº†è¶…æ—¶å¼‚å¸¸");
                                    logger.info("   æ¶ˆæ¯: {}", message);
                                } else {
                                    logger.warn("\nâš ï¸  è§¦å‘äº†å…¶ä»–å¼‚å¸¸");
                                    logger.warn("   æ¶ˆæ¯: {}", message);
                                }
                            }

                            if (exception.getCause() != null) {
                                logger.error("æ ¹æœ¬åŸå› : {}", exception.getCause().getClass().getName());
                                logger.error("åŸå› æ¶ˆæ¯: {}", exception.getCause().getMessage());
                            }

                        } else {
                            logger.info("âœ… æ¶ˆæ¯ #{} å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                                msgNum, metadata.partition(), metadata.offset());
                        }

                        testLatch.countDown();
                    }
                });

                logger.info("   æ¶ˆæ¯ #{} å·²æäº¤", i);
            }

            logger.warn("\nç­‰å¾… delivery.timeout.ms=30ç§’ è¶…æ—¶...");
            logger.warn("ï¼ˆå¦‚æœç£ç›˜å·²æ»¡ï¼ŒBroker æ— æ³•å†™å…¥ï¼Œåº”è¯¥ä¼šè¶…æ—¶ï¼‰\n");

            // å¯åŠ¨å€’è®¡æ—¶çº¿ç¨‹
            Thread countdownThread = new Thread(() -> {
                for (int i = 30; i > 0; i--) {
                    if (i % 10 == 0 || i <= 5) {
                        logger.info("   è¿˜éœ€ç­‰å¾…: {} ç§’...", i);
                    }
                    try {
                        Thread.sleep(1000);
                    } catch (InterruptedException e) {
                        break;
                    }
                    if (testLatch.getCount() == 0) {
                        logger.info("   æ‰€æœ‰æ¶ˆæ¯å¤„ç†å®Œæ¯•");
                        break;
                    }
                }
            });
            countdownThread.setDaemon(true);
            countdownThread.start();

            // ç­‰å¾…æ‰€æœ‰ Callback å®Œæˆï¼ˆæœ€å¤š 35 ç§’ï¼‰
            boolean completed = testLatch.await(35, TimeUnit.SECONDS);

            if (!completed) {
                logger.warn("âš ï¸  ç­‰å¾…è¶…æ—¶ï¼Œéƒ¨åˆ† Callback æœªæ‰§è¡Œ");
                logger.warn("   å¯èƒ½éœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´");
            }

        } catch (Exception e) {
            logger.error("\nå‘ç”Ÿå…¶ä»–å¼‚å¸¸: {}", e.getClass().getName());
            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", e.getMessage(), e);

        } finally {
            if (producer != null) {
                try {
                    logger.info("\n4. å…³é—­ KafkaProducer...");
                    producer.close(5, TimeUnit.SECONDS);
                    logger.info("   KafkaProducer å·²å…³é—­\n");
                } catch (Exception e) {
                    logger.debug("å…³é—­ producer æ—¶å‘ç”Ÿå¼‚å¸¸", e);
                }
            }

            logger.warn("\nâš ï¸  è®°å¾—æ¸…ç†ç£ç›˜ç©ºé—´:");
            logger.warn("   docker exec kafka-broker rm -f /kafka/kafka-logs-kafka/fillup.dat");
            logger.warn("   docker exec kafka-broker df -h /kafka\n");
        }
    }
}
