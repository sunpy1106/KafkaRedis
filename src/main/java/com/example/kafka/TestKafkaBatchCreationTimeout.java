package com.example.kafka;

import org.apache.kafka.clients.producer.Callback;
import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.clients.producer.RecordMetadata;
import org.apache.kafka.common.serialization.StringSerializer;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Properties;
import java.util.concurrent.CountDownLatch;
import java.util.concurrent.TimeUnit;

/**
 * æµ‹è¯•ç±»ï¼šè§¦å‘ Kafka Producer "batch creation" è¶…æ—¶å¼‚å¸¸
 *
 * ç›®æ ‡å¼‚å¸¸: "X ms has passed since batch creation"
 *
 * å…³é”®é…ç½®: delivery.timeout.ms
 */
public class TestKafkaBatchCreationTimeout {
    private static final Logger logger = LoggerFactory.getLogger(TestKafkaBatchCreationTimeout.class);

    public static void main(String[] args) {
        logger.info("========== æµ‹è¯• Kafka Batch Creation è¶…æ—¶å¼‚å¸¸ ==========\n");

        // æ–¹æ¡ˆ1: ä½¿ç”¨çœŸå® Kafka + æ‰‹åŠ¨åœæ­¢ï¼ˆæ¨èï¼Œæœ€å¯é ï¼‰
        testWithRealKafka();

        // æ–¹æ¡ˆ2: å¼‚æ­¥å‘é€ + é”™è¯¯ç«¯å£ï¼ˆå¤‡é€‰ï¼Œå¯èƒ½è§¦å‘ï¼‰
        // testAsyncWithWrongPort();

        logger.info("\n========== æµ‹è¯•å®Œæˆ ==========");
    }

    /**
     * æ–¹æ¡ˆ1: ä½¿ç”¨çœŸå® Kafka + æ‰‹åŠ¨åœæ­¢ï¼ˆæ¨èï¼‰â­â­â­â­â­
     *
     * æ­¥éª¤:
     *  1. ç¡®ä¿ Kafka æ­£åœ¨è¿è¡Œ: docker-compose up -d
     *  2. ç¨‹åºå‘é€æ¶ˆæ¯ï¼ˆå¼‚æ­¥ï¼‰
     *  3. æ‰‹åŠ¨åœæ­¢ Kafka: docker stop kafka-redis
     *  4. ç­‰å¾… delivery.timeout.ms è¶…æ—¶
     *  5. Callback æ”¶åˆ° "batch creation" è¶…æ—¶
     *
     * é…ç½®:
     *  - bootstrap.servers = localhost:9092 (çœŸå® Kafka)
     *  - delivery.timeout.ms = 30000 (30ç§’)
     *
     * é¢„æœŸ: Callback æ”¶åˆ°åŒ…å« "batch creation" çš„ TimeoutException
     */
    private static void testWithRealKafka() {
        logger.info("ã€æ–¹æ¡ˆ1ã€‘ä½¿ç”¨çœŸå® Kafka + æ‰‹åŠ¨åœæ­¢ï¼ˆæ¨èï¼‰");
        logger.warn("\nâš ï¸  å‡†å¤‡å·¥ä½œ:");
        logger.warn("   1. ç¡®ä¿ Kafka æ­£åœ¨è¿è¡Œ:");
        logger.warn("      docker-compose up -d");
        logger.warn("\n   2. ç¨‹åºå¯åŠ¨åï¼Œçœ‹åˆ°æç¤ºæ—¶ç«‹å³åœæ­¢ Kafka:");
        logger.warn("      docker stop kafka-redis");
        logger.warn("\n   3. æµ‹è¯•å®Œæˆåé‡å¯ Kafka:");
        logger.warn("      docker start kafka-redis\n");

        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9092");  // çœŸå® Kafka

        // âš ï¸ å…³é”®é…ç½®
        props.put("delivery.timeout.ms", "30000");  // 30ç§’è¶…æ—¶
        props.put("request.timeout.ms", "10000");   // 10ç§’è¯·æ±‚è¶…æ—¶
        props.put("linger.ms", "100");              // æ‰¹å¤„ç†å»¶è¿Ÿ
        props.put("batch.size", "16384");
        props.put("acks", "1");
        props.put("retries", "3");

        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());

        KafkaProducer<String, String> producer = null;
        final CountDownLatch latch = new CountDownLatch(1);
        final long startTime[] = {0};

        try {
            logger.info("1. åˆ›å»º KafkaProducerï¼ˆè¿æ¥åˆ°çœŸå® Kafkaï¼‰...");
            producer = new KafkaProducer<>(props);
            logger.info("   âœ… KafkaProducer åˆ›å»ºæˆåŠŸ\n");

            logger.info("2. å‘é€å¤šæ¡æ¶ˆæ¯ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰...");
            logger.info("   å°†å‘é€ 100 æ¡æ¶ˆæ¯ï¼Œæ¯æ¡å»¶è¿Ÿ 50ms\n");

            startTime[0] = System.currentTimeMillis();

            // å‘é€100æ¡æ¶ˆæ¯ï¼Œç»™è¶³å¤Ÿæ—¶é—´æ‰‹åŠ¨åœæ­¢ Kafka
            final int messageCount = 100;
            final CountDownLatch messageLatch = new CountDownLatch(messageCount);

            logger.warn("\nâš ï¸  âš ï¸  âš ï¸  è¯·ç«‹å³åœ¨å¦ä¸€ä¸ªç»ˆç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤åœæ­¢ Kafka:");
            logger.warn("   docker stop kafka-redis");
            logger.warn("\nå¼€å§‹å‘é€æ¶ˆæ¯ï¼Œæ¯50msä¸€æ¡ï¼Œå…±100æ¡...\n");

            for (int i = 0; i < messageCount; i++) {
                final int msgNum = i + 1;
                ProducerRecord<String, String> record =
                    new ProducerRecord<>("test-topic", "key-" + msgNum, "value-" + msgNum);

                // âœ… ä½¿ç”¨å¼‚æ­¥å‘é€ + Callback
                producer.send(record, new Callback() {
                    @Override
                    public void onCompletion(RecordMetadata metadata, Exception exception) {
                        long elapsed = System.currentTimeMillis() - startTime[0];

                        if (exception != null) {
                            logger.error("\nâŒ æ¶ˆæ¯ #{} å‘é€å¤±è´¥ï¼è€—æ—¶: {}ms ({} ç§’)", msgNum, elapsed, elapsed / 1000);
                            logger.error("å¼‚å¸¸ç±»å‹: {}", exception.getClass().getName());
                            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", exception.getMessage());

                            // âœ… æ£€æŸ¥æ˜¯å¦åŒ…å« "batch creation"
                            String message = exception.getMessage();
                            if (message != null && message.contains("batch creation")) {
                                logger.info("\nğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼");
                                logger.info("âœ… å¼‚å¸¸æ¶ˆæ¯åŒ…å«: 'batch creation'");
                                logger.info("âœ… å®Œæ•´æ¶ˆæ¯: {}", message);
                            } else if (message != null && message.contains("Expiring")) {
                                logger.info("\nğŸ¯ è§¦å‘äº†è¿‡æœŸå¼‚å¸¸ï¼ˆæ¶ˆæ¯ #{}ï¼‰ï¼", msgNum);
                                logger.info("âœ… å¼‚å¸¸æ¶ˆæ¯: {}", message);
                            } else {
                                logger.warn("\nâš ï¸  æ¶ˆæ¯ #{} è§¦å‘äº†å…¶ä»–è¶…æ—¶å¼‚å¸¸", msgNum);
                                logger.warn("   å¼‚å¸¸æ¶ˆæ¯: {}", message);
                            }

                        } else {
                            if (msgNum % 10 == 0 || msgNum <= 5) {
                                logger.info("âœ… æ¶ˆæ¯ #{} å‘é€æˆåŠŸ - Partition: {}, Offset: {}",
                                    msgNum, metadata.partition(), metadata.offset());
                            }
                        }

                        messageLatch.countDown();
                    }
                });

                // æ¯æ¡æ¶ˆæ¯ä¹‹é—´å»¶è¿Ÿ50msï¼Œç»™è¶³å¤Ÿæ—¶é—´åœæ­¢ Kafka
                try {
                    Thread.sleep(50);
                } catch (InterruptedException e) {
                    break;
                }
            }

            logger.warn("\nç­‰å¾…æ‰€æœ‰æ¶ˆæ¯çš„ Callback å®Œæˆï¼ˆæœ€å¤š 40 ç§’ï¼‰...\n");

            // ç­‰å¾… Callback å®Œæˆæˆ–è¶…æ—¶
            boolean completed = messageLatch.await(40, TimeUnit.SECONDS);

            if (!completed) {
                logger.warn("âš ï¸  ç­‰å¾…è¶…æ—¶ï¼ŒCallback æœªæ‰§è¡Œ");
            }

        } catch (Exception e) {
            logger.error("\nå‘ç”Ÿå…¶ä»–å¼‚å¸¸: {}", e.getClass().getName());
            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", e.getMessage(), e);

        } finally {
            if (producer != null) {
                try {
                    logger.info("\n3. å…³é—­ KafkaProducer...");
                    producer.close();
                    logger.info("   KafkaProducer å·²å…³é—­");
                } catch (Exception e) {
                    logger.debug("å…³é—­ producer æ—¶å‘ç”Ÿå¼‚å¸¸", e);
                }
            }

            logger.warn("\nâš ï¸  æµ‹è¯•å®Œæˆåï¼Œè®°å¾—é‡å¯ Kafka:");
            logger.warn("   docker start kafka-redis\n");
        }
    }

    /**
     * æ–¹æ¡ˆ2: å¼‚æ­¥å‘é€ + é”™è¯¯ç«¯å£ï¼ˆå¤‡é€‰ï¼‰
     *
     * é…ç½®:
     *  - bootstrap.servers = localhost:9999 (é”™è¯¯ç«¯å£)
     *  - delivery.timeout.ms = 10000 (10ç§’)
     *
     * æ³¨æ„: å¯èƒ½ä»ç„¶åœ¨ metadata é˜¶æ®µå¤±è´¥
     * é¢„æœŸ: å¯èƒ½è§¦å‘ "batch creation" æˆ– "metadata" è¶…æ—¶
     */
    private static void testAsyncWithWrongPort() {
        logger.info("\nã€æ–¹æ¡ˆ2ã€‘å¼‚æ­¥å‘é€ + é”™è¯¯ç«¯å£ï¼ˆå¤‡é€‰ï¼‰");
        logger.info("é…ç½®: bootstrap.servers=localhost:9999, delivery.timeout.ms=10000\n");

        Properties props = new Properties();
        props.put("bootstrap.servers", "localhost:9999");  // é”™è¯¯ç«¯å£

        // å°è¯•ç»•è¿‡ metadata é˜»å¡
        props.put("delivery.timeout.ms", "10000");  // 10ç§’
        props.put("request.timeout.ms", "3000");
        props.put("max.block.ms", "3000");  // å¿«é€Ÿ metadata è¶…æ—¶
        props.put("retries", "0");          // ä¸é‡è¯•

        props.put("key.serializer", StringSerializer.class.getName());
        props.put("value.serializer", StringSerializer.class.getName());

        KafkaProducer<String, String> producer = null;
        final CountDownLatch latch = new CountDownLatch(1);
        final long startTime[] = {0};

        try {
            logger.info("1. åˆ›å»º KafkaProducer...");
            producer = new KafkaProducer<>(props);
            logger.info("   KafkaProducer åˆ›å»ºæˆåŠŸ\n");

            logger.info("2. å‘é€æ¶ˆæ¯ï¼ˆå¼‚æ­¥æ¨¡å¼ï¼‰...");
            ProducerRecord<String, String> record =
                new ProducerRecord<>("test-topic", "test-key", "test-value");

            startTime[0] = System.currentTimeMillis();

            producer.send(record, new Callback() {
                @Override
                public void onCompletion(RecordMetadata metadata, Exception exception) {
                    long elapsed = System.currentTimeMillis() - startTime[0];

                    if (exception != null) {
                        logger.error("\nâŒ å‘é€å¤±è´¥ï¼è€—æ—¶: {}ms", elapsed);
                        logger.error("å¼‚å¸¸ç±»å‹: {}", exception.getClass().getName());
                        logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", exception.getMessage());

                        String message = exception.getMessage();
                        if (message != null) {
                            if (message.contains("batch creation")) {
                                logger.info("\nğŸ¯ æˆåŠŸè§¦å‘ Batch Creation è¶…æ—¶ï¼");
                            } else if (message.contains("metadata")) {
                                logger.warn("\nâš ï¸  è§¦å‘äº† Metadata è¶…æ—¶ï¼ˆä¸æ˜¯ç›®æ ‡é”™è¯¯ï¼‰");
                                logger.warn("   éœ€è¦ä½¿ç”¨æ–¹æ¡ˆ1ï¼ˆçœŸå® Kafka + æ‰‹åŠ¨åœæ­¢ï¼‰");
                            } else {
                                logger.warn("\nâš ï¸  è§¦å‘äº†å…¶ä»–å¼‚å¸¸");
                            }
                            logger.info("   æ¶ˆæ¯: {}", message);
                        }

                    } else {
                        logger.info("âœ… æ¶ˆæ¯å‘é€æˆåŠŸï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰");
                    }

                    latch.countDown();
                }
            });

            logger.info("   ç­‰å¾… Callback æ‰§è¡Œ...\n");

            // ç­‰å¾… Callback å®Œæˆ
            latch.await(15, TimeUnit.SECONDS);

        } catch (Exception e) {
            logger.error("\nå‘ç”Ÿå…¶ä»–å¼‚å¸¸: {}", e.getClass().getName());
            logger.error("å¼‚å¸¸æ¶ˆæ¯: {}", e.getMessage(), e);

        } finally {
            if (producer != null) {
                try {
                    producer.close();
                    logger.info("\nKafkaProducer å·²å…³é—­");
                } catch (Exception e) {
                    logger.debug("å…³é—­ producer æ—¶å‘ç”Ÿå¼‚å¸¸", e);
                }
            }
        }
    }
}
